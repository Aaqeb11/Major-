{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5d8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter import simpledialog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3aab7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\91863\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\91863\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense,Activation, BatchNormalization, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ac8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\91863\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b41fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = tkinter.Tk()\n",
    "main.title(\"Robust Intelligent Malware Detection using Deep learning\")\n",
    "main.geometry(\"1300x1200\")\n",
    "malImg_dataset=['Adialar.c','Agent.FYI','Allaple.A','Alueron.gen!j','Autorun.k','C2LOP.gen!g','C2LOP.P','Dialplatform.B','Dontovo.A','Fakerean','Instantaccess','Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT','Malex.gen!j','Obfuscator.AD','Rbot!gen','Skintrim.N','Swizzor.gen!E','Swizzor.gen!I','VB.AT','Wintrim.BX','Yuner.A']\n",
    "global filename\n",
    "global knn_precision,nb_precision,tree_precision,svm_precision,random_precision,cnn_precision,lstm_precision\n",
    "global knn_recall,nb_recall,tree_recall,svm_recall,random_recall,cnn_recall,lstm_recall\n",
    "global knn_fmeasure,nb_fmeasure,tree_fmeasure,svm_fmeasure,random_fmeasure,cnn_fmeasure,lstm_fmeasure\n",
    "global knn_acc,nb_acc,tree_acc,svm_fmeasure,random_fmeasure,cnn_fmeasure,lstm_fmeasure\n",
    "global classifier\n",
    "global X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fa6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lstmcnn(dataset, standardize=True):\n",
    "    features = dataset['arr'][:, 0]\n",
    "    features = np.array([feature for feature in features])\n",
    "    features = np.reshape(features, (features.shape[0], features.shape[1]*features.shape[2]))\n",
    "    if standardize:\n",
    "        features = StandardScaler().fit_transform(features)\n",
    "    labels = dataset['arr'][:, 1]\n",
    "    labels = np.array([label for label in labels])\n",
    "    print(labels.shape)\n",
    "    print(features.shape)\n",
    "    return features, labels\n",
    "\n",
    "def load_data(dataset, standardize=True):\n",
    "    features = dataset['arr'][:, 0]\n",
    "    features = np.array([feature for feature in features])\n",
    "    features = np.reshape(features, (features.shape[0], features.shape[1]*features.shape[2]))\n",
    "    if standardize:\n",
    "        features = StandardScaler().fit_transform(features)\n",
    "    labels = dataset['arr'][:, 1]\n",
    "    labels = np.array([label for label in labels])\n",
    "    feature = []\n",
    "    label = []\n",
    "    for i in range(0, 4000):\n",
    "        feature.append(features[i])\n",
    "        label.append(labels[i])\n",
    "    feature = np.asarray(feature)\n",
    "    label = np.asarray(label)\n",
    "    print(labels.shape)\n",
    "    print(features.shape)\n",
    "    print(label.shape)\n",
    "    print(feature.shape)\n",
    "    return feature, label\n",
    "\n",
    "def upload():\n",
    "    global filename\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    filename = filedialog.askopenfilename(initialdir=\"dataset\")\n",
    "    print('Malimg dataset loaded\\n')\n",
    "def prediction(X_test,cls):\n",
    "    y_pred=cls.predict(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "        print(\"X=%s,predicted=%s\"%(X_test,y_pred[i]))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632cd8c",
   "metadata": {},
   "source": [
    "# ML algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60d774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN():\n",
    "    global knn_precision\n",
    "    global knn_recall\n",
    "    global knn_fmeasure\n",
    "    global knn_acc\n",
    "    text.delete('1.0',END)\n",
    "    cls=KNeighborsclassifier(n_neighbors=10)\n",
    "    cls.fit(X_train,y_train)\n",
    "    text.insert(END,\"KNN prediction Results\\n\\n\")\n",
    "    prediction_Data=prediction(X_test,cls)\n",
    "    knn_precision=precision_score(y_test,prediction_Data,average='micro')*100\n",
    "    knn_recall=recall_score(y_test,prediction_Data,average='micro')*100\n",
    "    knn_fmeasure=f1_score(y_test,prediction_Data,average='micro')*100\n",
    "    knn_acc=accuracy_score(y_test,prediction_Data,average='micro')*100\n",
    "    text.insert(END,\"KNN Precison:\"+str(knn_precision)+\"\\n\")\n",
    "    text.insert(END,\"KNN recall:\"+str(knn_recall)+\"\\n\")\n",
    "    text.insert(END,\"KNN fmeasure:\"+str(knn_f1)+\"\\n\")\n",
    "    text.insert(END,\"KNN Accuracy:\"+str(knn_acc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7672d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayes():\n",
    "    global nb_precision\n",
    "    global nb_recall\n",
    "    global nb_fmeasure\n",
    "    global nb_acc\n",
    "    text.delete('1.0',END)\n",
    "    data,labels = load_data(np.load(filename,allow_pickle=True))\n",
    "    X_train,X_test,y_train,y_test=train_test_split(data,labels,test_size=0.2)\n",
    "    scalar=Normalize.fit(X_train)\n",
    "    X_train=scalar.transform(X_train)\n",
    "    scalar=Normalize.fit(X_test)\n",
    "    X_test=scalar.transform(X_test)\n",
    "    cls=BernoulliNB(binarize=0.0)\n",
    "    cls.fit(X_train,y_train)\n",
    "    text.insert(END,\"Naive bayes Prediction Results\\n\\n\")\n",
    "    prediction_Data=prediction(X_test,cls)\n",
    "    nb_precision=precision_score(y_test,prediction_Data,average='micro')*100\n",
    "    nb_recall=recall_score(y_test,prediction_Data,average='micro')*100\n",
    "    nb_fmeasure=f1_score(y_test,prediction_Data,average='micro')*100\n",
    "    nb_acc=accuracy_score(y_test,prediction_Data,average='micro')*100\n",
    "    text.insert(END,\"NB Precison:\"+str(NB_precision)+\"\\n\")\n",
    "    text.insert(END,\"NB recall:\"+str(NB_recall)+\"\\n\")\n",
    "    text.insert(END,\"NB fmeasure:\"+str(NB_f1)+\"\\n\")\n",
    "    text.insert(END,\"NB Accuracy:\"+str(NB_acc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b5a8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree():\n",
    "    text.delete('1.0',END)\n",
    "    global tree_precision\n",
    "    global tree_recall\n",
    "    global tree_fmeasure\n",
    "    global tree_acc\n",
    "    \n",
    "    rfc=DecisionTreeClassifier(criterion=\"entropy\",splitter=\"randon\",max_depth=20,min_samples_split=50,min_samples_leaf=20,max_features=5)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    text.insert(END,\"Decision Tree Prediction Results\\n\")\n",
    "    prediction_data=prediction(X_test,rfc)\n",
    "    tree_prediction = precision_score(y_test,prediction_data,average='micro')*100    \n",
    "    tree_recall = recall_score(y_test,prediction_data,average='micro')*100    \n",
    "    tree_fmeasure = f1_score(y_test,prediction_data,average='micro')*100    \n",
    "    tree_acc = accuracy_score(y_test,prediction_data,average='micro')*100    \n",
    "    \n",
    "    text.insert(END,\"Decision Tree Precision:\"+str(tree_precision)+\"\\n\")\n",
    "    text.insert(END,\"Decision Tree recall:\"+str(tree_recall)+\"\\n\")\n",
    "    text.insert(END,\"Decision Tree fmeasure:\"+str(tree_fmeasure)+\"\\n\")                        \n",
    "    text.insert(END,\"Decision Tree Accuracy:\"+str(tree_acc)+\"\\n\")                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca21dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    text.delete('1.0', END)\n",
    "    global random_acc\n",
    "    global random_precision\n",
    "    global random_recall \n",
    "    global random_fmeasure\n",
    "    rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "    rfc. fit(X_train, y_train)\n",
    "    text. insert(END, \"Random Forest Prediction Results In'\")\n",
    "    prediction_data = prediction(X_test, rfc)\n",
    "    random_precision = precision_score(y_test, prediction_data, average='micro')*100\n",
    "    random_recall = recall_score(y_test, prediction_data, average='micro')*100\n",
    "    random_fmeasure = fl_score(y_test,prediction_data,average='micro')*100\n",
    "    random_acc = accuracy_score(y_test,prediction_data)*100\n",
    "    text.insert(END,\"Random Forest Precision:\"+str(random_precision)+\"\\n\")\n",
    "    text.insert(END, \"Random Forest Recall:\"+ str(random_recall)+\"\\n\")\n",
    "    text.insert(END, \"Random Forest FMeasure:\"+ str(random_fimeasure)+\"\\n\")\n",
    "    text.insert(END, \"Random Forest Accuracy:\" + str(random_acc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe677f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM():\n",
    "    text.delete('1.0', END)\n",
    "    global svm_acc\n",
    "    global svm_precision\n",
    "    global svm_recall\n",
    "    global svm_fmeasure\n",
    "    global X_train, X_test, y_train,y_test\n",
    "    data, labels = load_data(np.load(filename,allow_pickle=True))\n",
    "    X_train, X_test,y_train,y_test=train_test_split(data,label,test_size=0.2)\n",
    "    print(\"hello \")\n",
    "    rfc = svm.SVC(C=2.0, gamma='scale',kernel='rbf',random_state=2)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    text.insert(END, \"SVM Prediction Results\\n\")\n",
    "    prediction_data = prediction(X_test,rfc)\n",
    "    svm_precision = precision_score(y_test, prediction_data,average='micro')*100\n",
    "    svm_recall = recall_score(y_test, prediction_data, average='micro')*100\n",
    "    svm_fmeasure = fl_score(y_test, prediction_data, average='micro')*100\n",
    "    svm_acc = accuracy_score(y_test,prediction_data) * 100\n",
    "    text.insert(END, \"SVM Precision : \" + str(svm_precision)+ \"\\n\")\n",
    "    text.insert(END, \"SVM Recall : \" + str(svm_recall) + \"\\n\") \n",
    "    text.insert(END, \"SVM FMeasure: \"+ str( svm_fmeasure) + \"\\n\")\n",
    "    text.insert(END, \"SVM Accuracy:\"+ str(svm_acc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a287bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL algorithms\n",
    "\n",
    "def LSTM():\n",
    "    global lstm_ace\n",
    "    global lstm_precision\n",
    "    global lstm_recall\n",
    "    global lstm_fmeasure\n",
    "    text.delete('1.0', END)\n",
    "    data, labels= load_lstmcnn(np.load(filename, allow_pickle= True))\n",
    "    labels= labels.reshape((9339, 1 ))\n",
    "    print(labels)\n",
    "    data= data.reshape((9339, 32, 32))\n",
    "    X_trainl, X_testl, y_trainl, y_testl =train_test_split(data, labels,test_size=0.101)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(y_train1)\n",
    "    print(y_train1.shape)\n",
    "    y_train1 = enc.transform(y_train1)\n",
    "    y_testl = enc.transform(y_testl)\n",
    "    # rehsaping traing\n",
    "    Print(\"X_train.shape before =\",X_train1.shape)\n",
    "    X_trainl = X_trainl.reshape((8395, 32, 32))\n",
    "    print(\"X_train.shape after = \",X_train1.shape)\n",
    "    print(\"y_train.shape = \", y_train1.shape)\n",
    "    # rehsaping testing\n",
    "    print(\"X_test.shape before = \",X_testl.shape)\n",
    "    X_testl = X_testl.reshape((944, 32, 32))\n",
    "    print(\"X_test.shape after = \",X_testl.shape)\n",
    "    print(\"y_test.shape = \", y_test1.shape)\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.LSTM(100,input_shape=(32, 32)))\n",
    "    model.add(Dropout( 0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(25, activation='softmax')) \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(X_train1,y_train1,epochs=8,batch_size=64)\n",
    "    prediction_data=model.predict(X_test1)\n",
    "    prediction_data=np.argmax(prediction_data,axis=1)\n",
    "    y_testl = np.argmnx(y_testl, axis=l)\n",
    "    lstm_precision = precision_score(y_test1, prediction_data, average='micro')*100\n",
    "    lstm_recall = recall_score(y_test1, prediction_data, average='micro')*100\n",
    "    lstm_fmeasure = fl_score(y_testl, prediction_data, average='micro')*100\n",
    "    lstm_acc = accuracy_score(y_test1, prediction_data)*100\n",
    "    text.insert(END, \"LSTM Prediction Results\\n\")\n",
    "    text.insert(END, \"LSTM Precision : \" + str(lstm_precision) + \"\\n\")\n",
    "    text.insert(END, \"LSTM Recall : \" + str(lstm_recall) + \"\\n\")\n",
    "    text.insert(END, \"LSTM FMeasure : \"+ str(lstm_fmeasure) + \"\\n\")\n",
    "    text.insert(END, \"LSTM Accuracy : \" + str(lstm_acc) + \"\\n\")\n",
    "    #scores= model.evaluate(X_test, y _test, verbose=0)\n",
    "    # print(\"Accuracy: %.2f0/4%\" % (scores[l]*l00)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c537b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    global cnn_ace\n",
    "    global cnn_precision\n",
    "    global cnn_recall\n",
    "    global cnn_fmeasure\n",
    "\n",
    "    text.delete('1.0', END)\n",
    "    data,labels== load_lstmcnn(np.load(filename, allow_pickle=True))\n",
    "    labels=labels.reshape( (9339, 1)) \n",
    "    print(labels)\n",
    "    data== data.reshape((9339, 32, 32))\n",
    "    X_train1, X_test1 , y_train1, y_test1 = train_test_split(data, labels,test_size=0.101)\n",
    "    enc == OneHotEncoder()\n",
    "    enc.fit(y_train1)\n",
    "    print(y_train1.shape)\n",
    "    y_train1 = enc.transform(y_train1)\n",
    "    y_test1 = enc.transform(y_test1)\n",
    "    # rehsaping traing\n",
    "    print(\"X_train.shape before = \", X_train1.shape)\n",
    "    X_trainl = X_trainl.reshape((8395, 32, 32, 1))\n",
    "    print(\"X_train.shape after = \", X_trainl.shape)\n",
    "    print(\"y_train.shape = \", y_trainl.shape)\n",
    "    # rehsaping testing\n",
    "    print(\"X_test.shape before = \", X_testl.shape)\n",
    "    X_test1= X_test1.reshape((944, 32, 32, 1 ))\n",
    "    Print(\"X_test.shape after = \", X_test1.shape)\n",
    "    Print(\" y_test.shape = \", y_test1.shape)\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Convolution2D(32,(3,3), border_mode='valid', input_shape=(32,32, 1)))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation(\"relu \"))\n",
    "    classifier.add(Convolution2D(32, (3, 3 ), border_mode='valid'))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation(\"relu \"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense( 128))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classitier.add(Activation(\"relu\"))\n",
    "    classifier.add(Dense(25))\n",
    "    classifier.add(BatchNormalization())\n",
    "    classifier.add(Activation(\" softmax \"))\n",
    "    classifier.compile( optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    classifier.fit(X_trainl, y_trainl, epochs=10, batch_size=64)\n",
    "    prediction_data = classifier.predict(X_testl)\n",
    "    prediction_data = np.argmax(prediction_data, axis= 1)\n",
    "    Y_testl = np.argmax(y_test1, axis=l)\n",
    "    cnn_precision= precision_score(y_test1,prediction_data, average='micro')*100\n",
    "    cnn_recall = recall_score(y_test1,prediction_data,average='micro')*100\n",
    "    cnn_fmeasure= fl_score(y_testl, prediction_data, average='micro')*100\n",
    "    cnn_acc = accuracy_score(y_test1, prediction_data)*100\n",
    "    text.insert(END, \"CNN Prediction llesults\\n\")\n",
    "    text.insert(END, \"CNN Precision : \" + str(cnn_precision) + \"\\n\")\n",
    "    text.insert(END, \"CNN llecall : \"+ str(cnn_recall) + \"\\n\")\n",
    "    text.inset1(END, \"CNN FMeasure : \"+ str(cnn_fmeasure) + \"\\n\")\n",
    "    text.insert(END, \"CNN Accuracy: \"+ str(cnn_acc) + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30ae39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    filename = filedialog.askopenfilename(initialdir=\"images\")\n",
    "    text.delete('1.0',END)\n",
    "    text.insert(END,filename+\"loaded\\n\\n\")\n",
    "    with open('model.json',\"r\") as json_file:\n",
    "        loaded_model_json=json_file.read()\n",
    "        loaded_model=model_from_json(loaded_model_json)\n",
    "        loaded_model._load_weights(\"model_weights.h5\")\n",
    "        loaded_model._make_predict_function()\n",
    "        print(loaded_model.summary())\n",
    "        img= np.load(filename)\n",
    "        img2arr = img.reshape(1,32,32,1)\n",
    "        preds = loaded_model.predict(im2arr)\n",
    "        print(str(preds)+\"\"+str.no.argmax(preds))\n",
    "        predict=np.argmax(preds)\n",
    "        text.insert(END,'Uploaded file contains malware from family:'+ malImg_dataset[predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2cd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already defined the 'height' and 'bars' variables\n",
    "def precisionGraph():\n",
    "    height = [knn_precision, nb_precision, tree_precision, svm_precision, random_precision, cnn_precision, lstm_precision]\n",
    "    bars = ('KNN Precision', 'NB Precision', 'DT Precision', 'SVM Precision', 'RFPrecision', 'CNN Precision', 'LSTM Precision')\n",
    "\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, height)\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6fb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallGraph():\n",
    "    height = [knn_recall, nb_recall, tree_recall, svm_recall, random_recall, cnn_recall, lstm_recall]\n",
    "    bars = ('KNN recall', 'NB recall', 'DT recall', 'SVM recall', 'RFrecall', 'CNN recall', 'LSTM recall')\n",
    "\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, height)\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b642f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscoreGraph():\n",
    "    height = [knn_fmeasure, nb_fmeasure, tree_fmeasure, svm_fmeasure,\n",
    "    random_fmeasure, cnn_fmeasure,lstm_fmeasure]\n",
    "    bars= ('KNN FScore', 'NB FScore', 'DT FScore', 'SVM FScore', 'RF FScore',\n",
    "    'CNN FScore', 'LSTM FScore')\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, height)\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f002487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyGraph():\n",
    "    height= [knn_acc, nb_acc, tree_acc, svn1_acc, random_acc, cnn_acc, lstm_acc]\n",
    "    bars= ('KNN ACC', 'NB ACC', 'DT ACC', 'SVM ACC', 'RF ACC', 'CNN Acc', 'LSTM ACC')\n",
    "    y_pos= np.arange(len(bars))\n",
    "    plt.bar(Y_pos, height)\n",
    "    plt.xricks(y_pos, bars)\n",
    "    pit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a1d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0003920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
